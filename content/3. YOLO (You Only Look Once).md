
YOLO (You Only Look Once) es un modelo de detección de objetos, en este caso vamos a utilizar la version 11 en su formato nano, pero existen otros formatos (n, s, m, l, x) a su vez también cuenta con distintas versiones para detección de objetos, segmentación de instancias, detección de pose, etc.

La empresa Ultralytics es la que esta actualizando YOLO, para más información sobre los distintos modelos de YOLO pincha [aquí](https://docs.ultralytics.com/models/yolo11/) 

# Entrenamiento de YOLO

Para entrenar a YOLO vamos a utilizar la API de Ultralytics

Para ellos debemos instalarla en un entorno de Python:
```pip 
pip install ultralytics
```

Antes de entrenar al modelo necesitamos un dataset, para crear uno revise el capitulo [[2. Creación de un Dataset|Creación de un Dataset]]

Una vez tengamos el dataset usaremos este código para entrenar al modelo.
```python title=train.py
# Importamos la libreria de Ultralytics
from Ultralytics import YOLO

# Importamos el modelo que vamos a utilizar (por defecto)
model = YOLO("yolo11-n.pt") 

# Entrenamos el modelo con el dataset creado anteriormente
results = model.train(data="/path/to/data.yaml", epochs="100") 
```

Puede informarse sobre los parámetros que pueden usarse en model.train() pinchado [aquí](https://docs.ultralytics.com/modes/train/#train-settings)

# Prueba con OpenCV

Primero instalamos OpenCV
```pip
pip install opencv-python
```

Y utilizamos la librería para crear una app que con la cámara de nuestro ordenador utilice YOLO para detectar los objetos que aparecen en escena.

```python title=opencv.py
import cv2

import numpy as np

from ultralytics import YOLO

  

# Cargar el modelo
model = YOLO("path/to/best.pt") 
# Remplaza la dirección con la del modelo que hemos entrenado antes

  

# Iniciar la cámara

cap = cv2.VideoCapture(0) # Usar el dispositivo 0 de cámara

  

while True:

ret, frame = cap.read()

if not ret:

break

  

# Convert frame to RGB (YOLO expects RGB images)

rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

  

# Perform YOLO detection

results = model.predict(rgb_frame, conf=0.5, verbose=False) # Set desired confidence threshold

  

# Parse the results

for result in results:

for box in result.boxes:

x1, y1, x2, y2 = map(int, box.xyxy[0].tolist()) # Bounding box coordinates

conf = box.conf[0] # Confidence score

cls = int(box.cls[0]) # Class ID

  

# Get class label (optional, customize this based on your dataset)

label = model.names[cls]

  

# Draw bounding box and label on the frame

cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

  

# Display the frame with detections

cv2.imshow("YOLO Detection", frame)

  

# Break on pressing 'q'

if cv2.waitKey(1) & 0xFF == ord('q'):

break

  

# Release resources

cap.release()

cv2.destroyAllWindows()
```

